{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cec8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e79c6",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc42ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(z):\n",
    "    # Subtract max for numerical stability\n",
    "    exps = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def to_one_hot(y, num_classes):\n",
    "    \"\"\"Converts integer labels (0, 1, 2) to one-hot ([[1,0,0], ...])\"\"\"\n",
    "    return np.eye(num_classes)[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38501964",
   "metadata": {},
   "source": [
    "ANN tailored for our CNN, backprop should return the gradients for input of flatten layer, same logic as in ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09a16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.input_len = self.layers[0]\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = [np.random.randn(self.layers[i], self.layers[i+1]) * 0.1 \n",
    "                        for i in range(len(self.layers)-1)] \n",
    "        self.biases = [np.zeros((1, self.layers[i+1])) \n",
    "                       for i in range(len(self.layers)-1)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.A_cache = [x]\n",
    "        self.Z_cache = []\n",
    "        A = x\n",
    "        for i in range(len(self.weights)):\n",
    "            Z = np.dot(A, self.weights[i]) + self.biases[i]\n",
    "            self.Z_cache.append(Z)\n",
    "            \n",
    "            # --- Activation Logic ---\n",
    "            if i < len(self.weights) - 1:\n",
    "                # Hidden Layers: ReLU\n",
    "                A = relu(Z)\n",
    "            else:\n",
    "                # Output Layer: Softmax (For Classification)\n",
    "                A = softmax(Z)\n",
    "                \n",
    "            self.A_cache.append(A)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, x, y_true, lr):\n",
    "        \"\"\"\n",
    "        y_true: Must be One-Hot Encoded shape (Batch, Num_Classes)\n",
    "        \"\"\"\n",
    "        y_pred = self.forward(x)\n",
    "        L = len(self.weights)\n",
    "        m = y_true.shape[0]\n",
    "        dW = [None] * L\n",
    "        dB = [None] * L\n",
    "        dZ = [None] * L\n",
    "\n",
    "        # --- Output Layer Gradients ---\n",
    "        # Derivative of Cross-Entropy with respect to Softmax input Z is simply: (Pred - Truth)\n",
    "        dZ[L-1] = y_pred - y_true\n",
    "        \n",
    "        dW[L-1] = np.matmul(self.A_cache[L-1].T, dZ[L-1]) / m\n",
    "        dB[L-1] = np.sum(dZ[L-1], axis=0, keepdims=True) / m\n",
    "\n",
    "        # --- Hidden Layers Gradients ---\n",
    "        for l in range(L-2, -1, -1):\n",
    "            dZ[l] = np.matmul(dZ[l+1], self.weights[l+1].T) * relu_derivative(self.Z_cache[l])\n",
    "            dW[l] = np.matmul(self.A_cache[l].T, dZ[l]) / m\n",
    "            dB[l] = np.sum(dZ[l], axis=0, keepdims=True) / m\n",
    "\n",
    "        # --- Update Weights ---\n",
    "        for l in range(L):\n",
    "            self.weights[l] -= lr * dW[l]\n",
    "            self.biases[l]  -= lr * dB[l]\n",
    "            \n",
    "        # --- Return Gradient to CNN ---\n",
    "        # dX = dZ[0] dot W[0].T\n",
    "        d_input = np.matmul(dZ[0], self.weights[0].T)\n",
    "        return d_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fd680",
   "metadata": {},
   "source": [
    "Main CNN class - One convolution layer then flatten then ANN to do digit classification on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a71e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, input_shape, num_filters, kernel_size, dense_layers, padding=0, stride=1):\n",
    "        \"\"\"\n",
    "        dense_layers: e.g. [64, 10] (where 10 is number of classes, 64 hidden neurons)\n",
    "        \"\"\"\n",
    "        self.n_c, self.h_in, self.w_in = input_shape  # Channels, Height, Width\n",
    "        self.n_f = num_filters\n",
    "        self.k = kernel_size\n",
    "        self.p = padding\n",
    "        self.s = stride\n",
    "\n",
    "        # Compute Output Dimensions of convolution layer\n",
    "        self.h_out = ((self.h_in - self.k + 2 * self.p) // self.s) + 1\n",
    "        self.w_out = ((self.w_in - self.k + 2 * self.p) // self.s) + 1\n",
    "        \n",
    "        if self.h_out <= 0 or self.w_out <= 0:\n",
    "            raise ValueError(f\"Invalid output size. Check params.\")\n",
    "\n",
    "        # Initialize Convolution Filters\n",
    "        self.conv_w = np.random.randn(self.n_f, self.n_c, self.k, self.k) * 0.1\n",
    "        self.conv_b = np.zeros((self.n_f, 1))\n",
    "\n",
    "        # The flatten layer size\n",
    "        fc_input_len = self.n_f * self.h_out * self.w_out\n",
    "        \n",
    "        # Structure: [Flattened_Size, Hidden..., Num_Classes]\n",
    "        ann_architecture = [fc_input_len] + dense_layers\n",
    "        self.ann = NeuralNet(ann_architecture)\n",
    "        \n",
    "        self.num_classes = dense_layers[-1] #  for one-hot conversion\n",
    "        print(f\"CNN Initialized. Output Classes: {self.num_classes}\")\n",
    "\n",
    "    def convolve_step(self, image, kernel):\n",
    "        # helper function to perform a single convolution step\n",
    "\n",
    "        # extract dimensions\n",
    "        h_in, w_in = image.shape\n",
    "        k_size = kernel.shape[0]\n",
    "\n",
    "        # Apply padding if needed\n",
    "        if self.p > 0:\n",
    "            image = np.pad(image, ((self.p, self.p), (self.p, self.p)), mode='constant')\n",
    "\n",
    "        out = np.zeros((self.h_out, self.w_out))\n",
    "\n",
    "        # loop thorugh every pizel of output\n",
    "        for i in range(self.h_out):\n",
    "            for j in range(self.w_out):\n",
    "\n",
    "                #check where sliding window starts\n",
    "                h_start, w_start = i * self.s, j * self.s\n",
    "                \n",
    "                # slice out our region to do convolution on\n",
    "                region = image[h_start : h_start+k_size, w_start : w_start+k_size]\n",
    "\n",
    "                # element wise multuiply and sum\n",
    "                out[i, j] = np.sum(region * kernel)\n",
    "        return out\n",
    "\n",
    "    def forward(self, X):\n",
    "        # forward pass through CNN\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # cache for backprop\n",
    "        self.X_cache = X \n",
    "        self.Z_conv = np.zeros((m, self.n_f, self.h_out, self.w_out))\n",
    "\n",
    "        # loop through every image\n",
    "        for i in range(m):\n",
    "            # loop through every filter\n",
    "            for f in range(self.n_f):\n",
    "                filter_sum = 0\n",
    "                # loop through every channel\n",
    "                for c in range(self.n_c):\n",
    "                    filter_sum += self.convolve_step(X[i, c], self.conv_w[f, c])\n",
    "                self.Z_conv[i, f] = filter_sum + self.conv_b[f] # add bias\n",
    "\n",
    "        self.flattened = self.Z_conv.reshape(m, -1) # m to keep batch size and -1 to squish all other into one dimension\n",
    "        return self.ann.forward(self.flattened)\n",
    "\n",
    "    def backward(self, Y_true, lr=0.01):\n",
    "        \"\"\"\n",
    "        Y_true: One-Hot Encoded\n",
    "        \"\"\"\n",
    "        # Backprop through ANN (Classification)\n",
    "        d_flat = self.ann.backward(self.flattened, Y_true, lr)\n",
    "        \n",
    "        #  Reshape back or say deflatten\n",
    "        d_Z_conv = d_flat.reshape(self.X_cache.shape[0], self.n_f, self.h_out, self.w_out)\n",
    "        \n",
    "        #  Conv Gradients\n",
    "        m = self.X_cache.shape[0]\n",
    "\n",
    "        # grad has same size as weights and biases\n",
    "        d_conv_w = np.zeros_like(self.conv_w)\n",
    "        d_conv_b = np.zeros_like(self.conv_b)\n",
    "\n",
    "        # for each image in batch\n",
    "        for i in range(m):\n",
    "\n",
    "            for f in range(self.n_f): # for each filter\n",
    "\n",
    "                d_conv_b[f] += np.sum(d_Z_conv[i, f]) # bias gradient is sum of all dZs for that filter\n",
    "\n",
    "                for c in range(self.n_c): # for each channel\n",
    "\n",
    "                    img_slice = self.X_cache[i, c] # original image slice\n",
    "\n",
    "                    if self.p > 0: img_slice = np.pad(img_slice, ((self.p,self.p),(self.p,self.p)), 'constant') # reapplies padding if necessary\n",
    "                    \n",
    "                    # loop through each weight in filter\n",
    "                    for h in range(self.k):\n",
    "                        for w in range(self.k):\n",
    "\n",
    "                            # define the region of conv operation and extract that slice.. \n",
    "                            vert_start = h\n",
    "                            vert_end = vert_start + self.s * self.h_out\n",
    "                            horiz_start = w\n",
    "                            horiz_end = horiz_start + self.s * self.w_out\n",
    "\n",
    "                            patch = img_slice[vert_start:vert_end:self.s, horiz_start:horiz_end:self.s]\n",
    "\n",
    "                            # multiply input pixel by error grad , basically convolution of dZ with input image\n",
    "                            if patch.shape == d_Z_conv[i, f].shape:\n",
    "                                d_conv_w[f, c, h, w] += np.sum(patch * d_Z_conv[i, f])\n",
    "\n",
    "        # Update Conv Weights and Biases\n",
    "        self.conv_w -= lr * (d_conv_w / m)\n",
    "        self.conv_b -= lr * (d_conv_b / m)\n",
    "\n",
    "\n",
    "    def train(self, X, Y, lr=0.01, epochs=10):\n",
    "        \"\"\"\n",
    "        Y can be shape (m,) [Integers] or (m, num_classes) [One-Hot]\n",
    "        \"\"\"\n",
    "        # Convert Y to one-hot if it isn't already\n",
    "        if Y.ndim == 1:\n",
    "            Y_one_hot = to_one_hot(Y.astype(int), self.num_classes)\n",
    "        else:\n",
    "            Y_one_hot = Y\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            # Forward\n",
    "            y_probs = self.forward(X)\n",
    "            \n",
    "            # Loss Calculation (Cross Entropy)\n",
    "            epsilon = 1e-15 # prevent log(0) or negative infinity\n",
    "            y_probs_clipped = np.clip(y_probs, epsilon, 1 - epsilon) # forces all pprobs to be within [epsilon, 1-epsilon]\n",
    "\n",
    "            # Cross-Entropy Loss\n",
    "            loss = -np.mean(np.sum(Y_one_hot * np.log(y_probs_clipped), axis=1))\n",
    "            \n",
    "            # Accuracy Calculation\n",
    "            predictions = np.argmax(y_probs, axis=1)\n",
    "            true_labels = np.argmax(Y_one_hot, axis=1)\n",
    "            acc = np.mean(predictions == true_labels)\n",
    "            \n",
    "            # Backward\n",
    "            self.backward(Y_one_hot, lr)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}: Loss = {loss:.4f}, Accuracy = {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7e83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "053b7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist_demo():\n",
    "    print(\"Loading MNIST data...\")\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    #  Normalize (0-255 -> 0-1)\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    #  Reshape to (Batch, Channels, Height, Width)\n",
    "    # Batch:-1 Calculate this dimension automatically based on the total number of items\n",
    "    # MNIST is grayscale, so it has 1 channel\n",
    "    x_train = x_train.reshape(-1, 1, 28, 28) \n",
    "    x_test = x_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    #  SUBSET DATA\n",
    "    # We will use only 500 images for training to keep runtime fast. \n",
    "    TRAIN_SIZE = 500\n",
    "    TEST_SIZE = 100\n",
    "    \n",
    "    x_train_sub = x_train[:TRAIN_SIZE]\n",
    "    y_train_sub = y_train[:TRAIN_SIZE]\n",
    "    x_test_sub = x_test[:TEST_SIZE]\n",
    "    y_test_sub = y_test[:TEST_SIZE]\n",
    "\n",
    "    print(f\"Training on {TRAIN_SIZE} images. Input shape: {x_train_sub.shape}\")\n",
    "\n",
    "    # --- Configuration ---\n",
    "    # Input: 1 channel, 28x28\n",
    "    # Conv: 4 filters of size 3x3\n",
    "    # Dense: 64 hidden neurons -> 10 output classes\n",
    "    input_shape = (1, 28, 28)\n",
    "    num_filters = 4   #  4 different feature maps   \n",
    "    kernel_size = 3   # Size of each filter\n",
    "    dense_layers = [64, 10] \n",
    "    \n",
    "    # Initialize CNN\n",
    "    cnn = CNN(input_shape, num_filters, kernel_size, dense_layers, padding=0, stride=1)\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nStarting Training \")\n",
    "    # Higher learning rate because batch size is small and data is normalized\n",
    "    cnn.train(x_train_sub, y_train_sub, lr=0.1, epochs=25,)\n",
    "\n",
    "    # --- Test ---\n",
    "    print(\"\\nEvaluatin on Test Set...\")\n",
    "    probs = cnn.forward(x_test_sub)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    acc = np.mean(preds == y_test_sub) ## average of boolean array of correct predictions\n",
    "    print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "733aa12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data...\n",
      "Training on 500 images. Input shape: (500, 1, 28, 28)\n",
      "CNN Initialized. Output Classes: 10\n",
      "\n",
      "Starting Training \n",
      "Epoch 1: Loss = 2.3651, Accuracy = 10.80%\n",
      "Epoch 2: Loss = 2.2936, Accuracy = 15.00%\n",
      "Epoch 3: Loss = 2.2488, Accuracy = 16.40%\n",
      "Epoch 4: Loss = 2.2089, Accuracy = 19.60%\n",
      "Epoch 5: Loss = 2.1676, Accuracy = 22.20%\n",
      "Epoch 6: Loss = 2.1203, Accuracy = 24.40%\n",
      "Epoch 7: Loss = 2.0632, Accuracy = 27.20%\n",
      "Epoch 8: Loss = 1.9929, Accuracy = 31.80%\n",
      "Epoch 9: Loss = 1.9056, Accuracy = 37.00%\n",
      "Epoch 10: Loss = 1.7994, Accuracy = 45.60%\n",
      "Epoch 11: Loss = 1.6739, Accuracy = 53.40%\n",
      "Epoch 12: Loss = 1.5343, Accuracy = 57.20%\n",
      "Epoch 13: Loss = 1.3895, Accuracy = 61.80%\n",
      "Epoch 14: Loss = 1.2481, Accuracy = 66.20%\n",
      "Epoch 15: Loss = 1.1173, Accuracy = 69.40%\n",
      "Epoch 16: Loss = 1.0019, Accuracy = 72.40%\n",
      "Epoch 17: Loss = 0.9030, Accuracy = 75.60%\n",
      "Epoch 18: Loss = 0.8195, Accuracy = 78.40%\n",
      "Epoch 19: Loss = 0.7503, Accuracy = 81.40%\n",
      "Epoch 20: Loss = 0.6927, Accuracy = 82.40%\n",
      "Epoch 21: Loss = 0.6446, Accuracy = 83.20%\n",
      "Epoch 22: Loss = 0.6035, Accuracy = 84.60%\n",
      "Epoch 23: Loss = 0.5683, Accuracy = 85.20%\n",
      "Epoch 24: Loss = 0.5375, Accuracy = 85.80%\n",
      "Epoch 25: Loss = 0.5103, Accuracy = 86.20%\n",
      "\n",
      "Evaluatin on Test Set...\n",
      "Test Accuracy: 72.00%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "run_mnist_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
